---
title: "Update Twitter MEP"
author: "Giorgio Comai (OBCT/CCI)"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
if (!require("pacman")) install.packages("pacman",  repos = "https://cloud.r-project.org") # for taking care of package installation/loading
pacman::p_load("tidyverse")
pacman::p_load("ROAuth")
pacman::p_load("rtweet")
pacman::p_load("stringr")
# pacman::p_load("devtools")
# devtools::install_github("mkearney/rtweet")
# library("rtweet")

dir.create(path = file.path("archive"), showWarnings = FALSE)
dir.create(path = file.path("DF"), showWarnings = FALSE)
dir.create(path = file.path("logs"), showWarnings = FALSE)

twitter_token <- readRDS(file = "twitter_token.rds")
```



```{r updateTweets, eval=TRUE, message=FALSE, warning=FALSE}
# get list of all users
fileInfo <- file.info(list.files(path = file.path("DF"), full.names = TRUE))

users <- stringr::str_replace_all(string = list.files(path = file.path("DF")),
                                  pattern = stringr::fixed(".rds"), 
                                  replacement = "")
newTweets <- tibble::data_frame(users = users, newTweets = NA)

for (i in order(fileInfo$mtime)) {  # start processing by oldest modified
  stored <- readRDS(file = rownames(fileInfo)[i])
  if (is.null(stored)==FALSE) { # 
    # if there's an error, print it but go ahead
    temp <- tryCatch(expr = get_timeline(user = users[i], n = 3200, min_id = max(stored$status_id)),
                     error = function(e) {
                       # do nothing
                     })
    # if Twitter throws back anything looking real, add it to stored file
    if (is.null(temp)==FALSE) {
      if (nrow(temp)>0) {
        if (is.na(temp$screen_name[1])==FALSE){
          preSave <- bind_rows(temp, stored) %>% distinct(status_id, .keep_all = TRUE) %>% arrange(created_at)
          saveRDS(object = preSave, file = file.path("DF", paste0(users[i], ".rds")))
          # store how many new tweets in data frame for reference
          newTweets$newTweets[i] <- nrow(preSave)-nrow(stored)
          message(paste(newTweets[i,], collapse = " - "))
          Sys.sleep(time = 1)
        }
      }
    }
  }
}
knitr::kable(x = newTweets %>% arrange())
```

# Pre-process data

Include only data for the last 91 days, and remove retweets. 

```{r}
# transform into data frame

allMEPtweetsDF <- setNames(data.frame(matrix(ncol = 9, nrow = 0)), c("screen_name", "date", "text", "status_id", "retweet_count", "favorite_count", "lang", "hashtags", "urls_expanded"))

for (i in list.files(path = file.path("DF"), full.names = TRUE)) {
  temp <- readRDS(file = i) 
  if (is.null(temp)==FALSE) {
    allMEPtweetsDF <- bind_rows(allMEPtweetsDF, temp %>%
                                  distinct(status_id, .keep_all = TRUE) %>%
                                  mutate(date = as.Date(created_at)) %>% 
                                  filter(date>(Sys.Date()-91)) %>% 
                                  filter(is_retweet==FALSE)) %>% 
      select(screen_name, date, text, status_id, retweet_count, favorite_count, lang, hashtags, urls_expanded)
  }
}

## clean text

allMEPtweetsDF$clean_text <- stringr::str_replace_all(
  string = allMEPtweetsDF$text,
  pattern = stringr::regex(pattern = "@[[:alnum:]]+|#[[:alnum:]]+|http[[:graph:]]+|RT ", ignore_case = FALSE), replacement = "")

allMEPtweetsDF$clean_text <- stringr::str_replace_all(string = allMEPtweetsDF$clean_text, pattern = stringr::fixed("&amp;"), replacement = "&") 

allMEPtweetsDF$Link <- paste0("<a href='https://twitter.com/", allMEPtweetsDF$screen_name, "/status/", allMEPtweetsDF$status_id, "'>Source</a>")

```

Feed datasets to QuoteFinder

```{r}
dataFolder <- "/srv/shiny-server/QuoteFinderApp/data"
dir.create(dataFolder, showWarnings = FALSE)

# merge with initial data frame to include more details on MEPs
#allMEPfull <- left_join(allMEPtweetsDF, MEPsDF %>% rename(screen_name = SCREEN_NAME), by = "screen_name")

saveRDS(object = allMEPtweetsDF, file = file.path(dataFolder, "dataset.rds"))  

lang <- data_frame(lang = unlist(allMEPtweetsDF$lang)) %>%
  tidyr::drop_na() %>%
  count(lang, sort = TRUE) %>% select(lang)
langL <- as.list(lang$lang)

saveRDS(object = langL, file = file.path(dataFolder, "lang.rds"))   

hashtags <- vector("list", length = length(langL))
hashtags <- setNames(object = hashtags, nm = unlist(langL))
for (i in seq_along(langL)) {
  temp <- data_frame(hashtags = allMEPtweetsDF %>%
                       filter(lang==langL[[i]]) %>%
                       select(hashtags) %>% 
                       unlist()) %>% 
    tidyr::drop_na()  %>%
    count(hashtags, sort = TRUE) %>% select(hashtags)
  tempL <- as.list(temp$hashtags)
  if (length(tempL) == 0) {
     names(tempL) <- NULL
  } else {
    names(tempL) <- paste0("#", unlist(tempL))
  }
  hashtags[[i]] <- tempL
}

saveRDS(object = hashtags, file = file.path(dataFolder, "hashtags.rds"))

```

